"""
VIDOCQ BRAIN - Core Logic Module
The Universal Radar: Classify -> Memorize -> Alert

This module is the central intelligence that:
1. PROFILES the target (Person, Company, State)
2. CONSULTS memory (Neo4j) for past knowledge
3. GENERATES investigation strategy
4. PREDICTS dangers based on patterns
"""

from enum import Enum
from typing import Dict, List, Any, Optional, Tuple
from pydantic import BaseModel, Field
from datetime import datetime
import google.generativeai as genai

from src.core.logging import get_logger
from src.storage.graph import GraphStore
from src.config import settings

logger = get_logger(__name__)


# ============================================
# TARGET CLASSIFICATION
# ============================================

class TargetType(str, Enum):
    """The 3 Universal Target Types"""
    COMPANY = "COMPANY"      # Vision Économique
    PERSON = "PERSON"        # Vision Réputation & Influence
    STATE = "STATE"          # Vision Géopolitique
    UNKNOWN = "UNKNOWN"


class RiskLevel(str, Enum):
    """Risk assessment levels"""
    CRITICAL = "CRITICAL"
    HIGH = "HIGH"
    MEDIUM = "MEDIUM"
    LOW = "LOW"
    UNKNOWN = "UNKNOWN"


class TargetProfile(BaseModel):
    """Complete profile of an investigation target"""
    name: str
    target_type: TargetType
    confidence: float = Field(ge=0, le=1)
    
    # Classification details
    detected_indicators: List[str] = []
    probable_country: Optional[str] = None
    probable_sector: Optional[str] = None
    
    # Investigation strategy
    search_strategy: List[str] = []
    priority_sources: List[str] = []
    risk_keywords: List[str] = []
    
    # Memory context
    memory_context: Dict[str, Any] = {}
    known_risk_flags: List[str] = []
    connected_investigations: List[str] = []


class PredictiveAlert(BaseModel):
    """Alert generated by the brain"""
    alert_type: str
    risk_level: RiskLevel
    message: str
    evidence: List[str] = []
    recommendation: str
    generated_at: datetime = Field(default_factory=datetime.utcnow)


# ============================================
# THE BRAIN - CORE LOGIC
# ============================================

class VidocqBrain:
    """
    The Universal Brain of Vidocq.
    
    Process: CARTOGRAPHIER -> MÉMORISER -> ALERTER
    
    Capabilities:
    1. Target Classification (Person / Company / State)
    2. Memory Consultation (Learn from past investigations)
    3. Strategy Generation (Adapt to target type)
    4. Predictive Analysis (Alert on dangers)
    """
    
    def __init__(self):
        self.graph_store = GraphStore()
        
        if settings.GEMINI_API_KEY:
            genai.configure(api_key=settings.GEMINI_API_KEY)
            self.model = genai.GenerativeModel(settings.GEMINI_MODEL)
        else:
            self.model = None
            logger.warning("Brain initialized without LLM - limited functionality")
        
        # Risk patterns learned from doctrine
        self.risk_patterns = self._load_doctrine()
    
    def _load_doctrine(self) -> Dict[str, List[str]]:
        """Load the sovereign doctrine - what we protect, what we fear"""
        return {
            # Critical sectors (France)
            "critical_sectors": [
                "nuclear", "defense", "aerospace", "semiconductor",
                "pharmaceuticals", "telecommunications", "energy"
            ],
            # Hostile actors
            "hostile_indicators": [
                "sanctions", "OFAC", "money laundering", "shell company",
                "offshore", "panama papers", "beneficial owner hidden"
            ],
            # Supply chain risks
            "supply_risks": [
                "single supplier", "chinese dependency", "rare earth",
                "tier-3 unknown", "no audit"
            ]
        }
    
    # ============================================
    # STEP 1: CLASSIFY TARGET
    # ============================================
    
    async def classify_target(self, user_input: str) -> TargetProfile:
        """
        First step: Determine if target is Person, Company, or State.
        This changes the entire investigation strategy.
        """
        logger.info("brain_classifying", target=user_input)
        
        if not self.model:
            return self._fallback_classification(user_input)
        
        prompt = f"""Tu es un analyste de renseignement. Classifie cette cible.

CIBLE: "{user_input}"

Réponds UNIQUEMENT en JSON valide:
{{
    "target_type": "COMPANY" | "PERSON" | "STATE",
    "confidence": 0.0-1.0,
    "indicators": ["liste des indices qui t'ont fait choisir"],
    "probable_country": "pays d'origine probable ou null",
    "probable_sector": "secteur d'activité ou null"
}}

RÈGLES DE CLASSIFICATION:
- COMPANY: Suffixes (SA, Corp, Ltd, GmbH), noms de marques, entreprises
- PERSON: Prénom + Nom, titres (CEO, Président, Oligarque)
- STATE: Pays, Ministères, Gouvernements, Organisations internationales

Sois précis. Un nom comme "Apple" = COMPANY. "Tim Cook" = PERSON. "China" = STATE."""

        try:
            response = self.model.generate_content(
                prompt,
                generation_config={"temperature": 0.1, "max_output_tokens": 500}
            )
            
            import json
            text = response.text.strip()
            if "```" in text:
                text = text.split("```")[1]
                if text.startswith("json"):
                    text = text[4:]
            
            data = json.loads(text)
            
            return TargetProfile(
                name=user_input,
                target_type=TargetType(data.get("target_type", "UNKNOWN")),
                confidence=data.get("confidence", 0.5),
                detected_indicators=data.get("indicators", []),
                probable_country=data.get("probable_country"),
                probable_sector=data.get("probable_sector"),
                search_strategy=self._get_strategy_for_type(
                    TargetType(data.get("target_type", "UNKNOWN"))
                ),
                priority_sources=self._get_sources_for_type(
                    TargetType(data.get("target_type", "UNKNOWN"))
                ),
                risk_keywords=self._get_risks_for_type(
                    TargetType(data.get("target_type", "UNKNOWN"))
                )
            )
            
        except Exception as e:
            logger.error("classification_failed", error=str(e))
            return self._fallback_classification(user_input)
    
    def _fallback_classification(self, user_input: str) -> TargetProfile:
        """Fallback classification without LLM"""
        # Simple heuristics
        words = user_input.split()
        
        # Check for company indicators
        company_suffixes = ["sa", "corp", "inc", "ltd", "gmbh", "sas", "sarl"]
        if any(word.lower() in company_suffixes for word in words):
            return TargetProfile(
                name=user_input,
                target_type=TargetType.COMPANY,
                confidence=0.7,
                detected_indicators=["Company suffix detected"],
                search_strategy=self._get_strategy_for_type(TargetType.COMPANY),
                priority_sources=self._get_sources_for_type(TargetType.COMPANY),
                risk_keywords=self._get_risks_for_type(TargetType.COMPANY)
            )
        
        # Check for state indicators
        if len(words) == 1 and words[0][0].isupper():
            return TargetProfile(
                name=user_input,
                target_type=TargetType.STATE,
                confidence=0.5,
                detected_indicators=["Single capitalized word - possible country"],
                search_strategy=self._get_strategy_for_type(TargetType.STATE),
                priority_sources=self._get_sources_for_type(TargetType.STATE),
                risk_keywords=self._get_risks_for_type(TargetType.STATE)
            )
        
        # Check for person indicators (2-3 words, both capitalized)
        if 2 <= len(words) <= 3 and all(w[0].isupper() for w in words):
            return TargetProfile(
                name=user_input,
                target_type=TargetType.PERSON,
                confidence=0.6,
                detected_indicators=["Name pattern detected"],
                search_strategy=self._get_strategy_for_type(TargetType.PERSON),
                priority_sources=self._get_sources_for_type(TargetType.PERSON),
                risk_keywords=self._get_risks_for_type(TargetType.PERSON)
            )
        
        # Default to company
        return TargetProfile(
            name=user_input,
            target_type=TargetType.COMPANY,
            confidence=0.4,
            detected_indicators=["Default classification"],
            search_strategy=self._get_strategy_for_type(TargetType.COMPANY),
            priority_sources=self._get_sources_for_type(TargetType.COMPANY),
            risk_keywords=self._get_risks_for_type(TargetType.COMPANY)
        )
    
    def _get_strategy_for_type(self, target_type: TargetType) -> List[str]:
        """Get investigation strategy based on target type"""
        strategies = {
            TargetType.COMPANY: [
                "map_supply_chain_upstream",      # Fournisseurs
                "map_supply_chain_downstream",    # Clients
                "identify_beneficial_owners",     # UBO
                "check_subsidiaries",             # Filiales
                "analyze_financial_health",       # Santé financière
                "detect_foreign_investment"       # Investissements étrangers
            ],
            TargetType.PERSON: [
                "map_social_graph",               # Réseau d'influence
                "check_corporate_positions",      # Mandats
                "search_leak_databases",          # Panama Papers, etc.
                "analyze_wealth_sources",         # Origine patrimoine
                "check_sanctions_lists",          # Sanctions
                "detect_pep_status"               # Personne politiquement exposée
            ],
            TargetType.STATE: [
                "analyze_resource_flows",         # Flux de ressources
                "map_strategic_alliances",        # Alliances
                "track_defense_spending",         # Budget défense
                "detect_embargo_signals",         # Signaux d'embargo
                "analyze_tech_dependencies",      # Dépendances technologiques
                "monitor_export_changes"          # Changements d'exportation
            ]
        }
        return strategies.get(target_type, strategies[TargetType.COMPANY])
    
    def _get_sources_for_type(self, target_type: TargetType) -> List[str]:
        """Get priority sources for investigation"""
        sources = {
            TargetType.COMPANY: [
                "opencorporates.com", "societe.com", "pappers.fr",
                "sec.gov", "gleif.org", "dnb.com"
            ],
            TargetType.PERSON: [
                "opensanctions.org", "icij.org", "linkedin.com",
                "wikileaks.org", "occrp.org"
            ],
            TargetType.STATE: [
                "trademap.org", "sipri.org", "worldbank.org",
                "un.org", "nato.int", "oec.world"
            ]
        }
        return sources.get(target_type, sources[TargetType.COMPANY])
    
    def _get_risks_for_type(self, target_type: TargetType) -> List[str]:
        """Get risk keywords to watch for"""
        risks = {
            TargetType.COMPANY: [
                "bankruptcy", "acquisition hostile", "delisting",
                "supply chain disruption", "sanctions", "fraud"
            ],
            TargetType.PERSON: [
                "money laundering", "corruption", "sanctions", "PEP",
                "offshore", "shell company", "influence operation"
            ],
            TargetType.STATE: [
                "embargo", "war", "conflict", "sanctions", "coup",
                "resource stockpiling", "alliance shift"
            ]
        }
        return risks.get(target_type, risks[TargetType.COMPANY])
    
    # ============================================
    # STEP 2: CONSULT MEMORY
    # ============================================
    
    async def consult_memory(self, target: str, profile: TargetProfile) -> Dict[str, Any]:
        """
        Check if we already know something about this target.
        This is the COGNITIVE MEMORY that learns from past investigations.
        """
        logger.info("brain_consulting_memory", target=target)
        
        memory_context = {
            "already_known": False,
            "existing_entity_id": None,
            "risk_flags": [],
            "connected_entities": [],
            "past_investigations": [],
            "relevant_patterns": []
        }
        
        try:
            # Query 1: Do we know this entity directly?
            direct_query = """
            MATCH (e:Entity)
            WHERE toLower(e.canonical_name) CONTAINS toLower($name)
               OR toLower(e.id) CONTAINS toLower($name)
            RETURN e.id as id, e.canonical_name as name, labels(e) as types,
                   e.first_seen as first_seen
            LIMIT 5
            """
            
            with self.graph_store.driver.session() as session:
                result = session.run(direct_query, name=target)
                records = list(result)
                
                if records:
                    memory_context["already_known"] = True
                    memory_context["existing_entity_id"] = records[0]["id"]
                    
                    for record in records:
                        memory_context["connected_entities"].append({
                            "id": record["id"],
                            "name": record["name"],
                            "types": record["types"]
                        })
            
            # Query 2: Check for risky connections
            if memory_context["already_known"]:
                risk_query = """
                MATCH (e:Entity)-[r]-(connected:Entity)
                WHERE e.id = $entity_id
                  AND (r.confidence_score < 0.5 
                       OR connected.canonical_name CONTAINS 'SANCTION'
                       OR type(r) IN ['LAUNDERS_THROUGH', 'BENEFICIAL_OWNER_OF'])
                RETURN connected.canonical_name as entity,
                       type(r) as relation,
                       r.confidence_score as confidence
                LIMIT 10
                """
                
                with self.graph_store.driver.session() as session:
                    result = session.run(
                        risk_query, 
                        entity_id=memory_context["existing_entity_id"]
                    )
                    for record in result:
                        memory_context["risk_flags"].append({
                            "entity": record["entity"],
                            "relation": record["relation"],
                            "confidence": record["confidence"]
                        })
            
            # Query 3: Pattern matching with doctrine
            for pattern_type, keywords in self.risk_patterns.items():
                for keyword in keywords:
                    if keyword.lower() in target.lower():
                        memory_context["relevant_patterns"].append({
                            "type": pattern_type,
                            "keyword": keyword,
                            "action": "HIGH_PRIORITY_INVESTIGATION"
                        })
            
            logger.info(
                "memory_consultation_complete",
                already_known=memory_context["already_known"],
                risk_flags=len(memory_context["risk_flags"])
            )
            
        except Exception as e:
            logger.error("memory_consultation_failed", error=str(e))
        
        return memory_context
    
    # ============================================
    # STEP 3: GENERATE INVESTIGATION PLAN
    # ============================================
    
    async def generate_investigation_plan(
        self,
        profile: TargetProfile,
        memory: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Generate the complete investigation plan.
        This is sent to the Discovery and Extraction modules.
        """
        logger.info("brain_generating_plan", target=profile.name, type=profile.target_type)
        
        # Build search queries based on target type
        queries = self._build_queries(profile)
        
        # Determine investigation priority
        priority = self._calculate_priority(profile, memory)
        
        plan = {
            "target": profile.name,
            "target_type": profile.target_type.value,
            "classification_confidence": profile.confidence,
            
            # Investigation strategy
            "strategy": profile.search_strategy,
            "priority_sources": profile.priority_sources,
            "risk_keywords": profile.risk_keywords,
            
            # Search queries
            "queries": queries,
            
            # Memory context
            "memory": {
                "already_known": memory.get("already_known", False),
                "existing_flags": memory.get("risk_flags", []),
                "connected_investigations": memory.get("past_investigations", [])
            },
            
            # Priority & configuration
            "priority": priority,
            "max_depth": 3 if priority == "HIGH" else 2,
            "max_sources": 10 if priority == "HIGH" else 5,
            
            # Metadata
            "generated_at": datetime.utcnow().isoformat(),
            "version": "5.0.0"
        }
        
        return plan
    
    def _build_queries(self, profile: TargetProfile) -> List[Dict[str, str]]:
        """Build search queries tailored to target type"""
        queries = []
        name = profile.name
        
        if profile.target_type == TargetType.COMPANY:
            queries = [
                {"query": f"{name} supply chain suppliers", "focus": "upstream"},
                {"query": f"{name} customers clients", "focus": "downstream"},
                {"query": f"{name} beneficial owner shareholder", "focus": "ownership"},
                {"query": f"{name} acquisition merger", "focus": "corporate_changes"},
                {"query": f'"{name}" sanctions OFAC', "focus": "compliance"},
            ]
        
        elif profile.target_type == TargetType.PERSON:
            queries = [
                {"query": f"{name} biography career", "focus": "background"},
                {"query": f"{name} board director company", "focus": "positions"},
                {"query": f"{name} panama papers offshore", "focus": "leaks"},
                {"query": f"{name} net worth assets", "focus": "wealth"},
                {"query": f"{name} controversy scandal", "focus": "reputation"},
            ]
        
        elif profile.target_type == TargetType.STATE:
            queries = [
                {"query": f"{name} exports imports trade", "focus": "trade_flows"},
                {"query": f"{name} military defense budget", "focus": "defense"},
                {"query": f"{name} strategic alliance partnership", "focus": "alliances"},
                {"query": f"{name} sanctions embargo", "focus": "restrictions"},
                {"query": f"{name} rare earth resources mining", "focus": "resources"},
            ]
        
        return queries
    
    def _calculate_priority(
        self, 
        profile: TargetProfile, 
        memory: Dict[str, Any]
    ) -> str:
        """Calculate investigation priority based on profile and memory"""
        
        # High priority conditions
        if memory.get("risk_flags"):
            return "HIGH"
        
        if profile.probable_sector in self.risk_patterns["critical_sectors"]:
            return "HIGH"
        
        if any(kw in profile.name.lower() for kw in ["bank", "nuclear", "defense"]):
            return "HIGH"
        
        # Medium priority conditions
        if memory.get("already_known"):
            return "MEDIUM"
        
        if profile.confidence > 0.7:
            return "MEDIUM"
        
        return "NORMAL"
    
    # ============================================
    # STEP 4: PREDICTIVE ANALYSIS
    # ============================================
    
    async def generate_alerts(
        self,
        profile: TargetProfile,
        memory: Dict[str, Any],
        graph_analysis: Optional[Dict] = None
    ) -> List[PredictiveAlert]:
        """
        Generate predictive alerts based on patterns.
        This is the "ALERTER" step - predicting dangers.
        """
        alerts = []
        
        # Alert 1: Known risky connections
        if memory.get("risk_flags"):
            alerts.append(PredictiveAlert(
                alert_type="KNOWN_RISK_CONNECTION",
                risk_level=RiskLevel.HIGH,
                message=f"Target has {len(memory['risk_flags'])} known risky connections from past investigations",
                evidence=[f"{f['entity']} ({f['relation']})" for f in memory["risk_flags"]],
                recommendation="Prioritize due diligence on these connections"
            ))
        
        # Alert 2: Critical sector
        if profile.probable_sector in self.risk_patterns["critical_sectors"]:
            alerts.append(PredictiveAlert(
                alert_type="CRITICAL_SECTOR",
                risk_level=RiskLevel.MEDIUM,
                message=f"Target operates in critical sector: {profile.probable_sector}",
                evidence=["LPM/OIV classification applies"],
                recommendation="Apply enhanced scrutiny for foreign investment"
            ))
        
        # Alert 3: Pattern match from doctrine
        for pattern in memory.get("relevant_patterns", []):
            alerts.append(PredictiveAlert(
                alert_type="DOCTRINE_PATTERN_MATCH",
                risk_level=RiskLevel.MEDIUM,
                message=f"Pattern detected: {pattern['type']} - {pattern['keyword']}",
                evidence=[f"Keyword match in target name/sector"],
                recommendation="Verify against sovereign doctrine requirements"
            ))
        
        # Alert 4: First-time investigation (no memory)
        if not memory.get("already_known"):
            alerts.append(PredictiveAlert(
                alert_type="FIRST_INVESTIGATION",
                risk_level=RiskLevel.LOW,
                message="First investigation of this target - no historical data",
                evidence=[],
                recommendation="Conduct comprehensive initial mapping"
            ))
        
        logger.info("alerts_generated", count=len(alerts))
        return alerts
    
    # ============================================
    # MAIN ENTRY POINT
    # ============================================
    
    async def analyze(self, user_input: str) -> Dict[str, Any]:
        """
        Main entry point: Run complete brain analysis.
        
        Returns complete analysis including:
        - Target profile (classification)
        - Memory context (what we already know)
        - Investigation plan (what to search)
        - Predictive alerts (dangers detected)
        """
        logger.info("brain_analysis_started", input=user_input)
        
        # Step 1: Classify
        profile = await self.classify_target(user_input)
        
        # Step 2: Consult Memory
        memory = await self.consult_memory(user_input, profile)
        profile.memory_context = memory
        profile.known_risk_flags = [f["entity"] for f in memory.get("risk_flags", [])]
        
        # Step 3: Generate Plan
        plan = await self.generate_investigation_plan(profile, memory)
        
        # Step 4: Generate Alerts
        alerts = await self.generate_alerts(profile, memory)
        
        result = {
            "status": "success",
            "target": user_input,
            "profile": profile.model_dump(),
            "memory": memory,
            "investigation_plan": plan,
            "alerts": [a.model_dump() for a in alerts],
            "analyzed_at": datetime.utcnow().isoformat()
        }
        
        logger.info(
            "brain_analysis_complete",
            target=user_input,
            type=profile.target_type.value,
            alerts=len(alerts)
        )
        
        return result
    
    # ============================================
    # CASCADE: AUTO-SCAN DIRECTORS FOR COMPANIES
    # ============================================
    
    async def cascade_scan_directors(
        self,
        company_name: str,
        max_directors: int = 5
    ) -> Dict[str, Any]:
        """
        For COMPANY targets: Automatically find and ghost-scan key directors.
        
        This cascade reveals:
        - CEO/CFO/Board members with suspicious profiles
        - Directors with no digital footprint (synthetic identities)
        - Key persons connected to risky entities
        """
        from src.brain.negative_space import NegativeSpaceAnalyzer, SuspicionLevel
        
        logger.info("cascade_scan_started", company=company_name)
        
        results = {
            "company": company_name,
            "directors_found": [],
            "directors_scanned": [],
            "suspicious_directors": [],
            "clean_directors": [],
            "overall_company_risk": "LOW"
        }
        
        try:
            # Step 1: Find directors/key persons in the graph
            query = """
            MATCH (company:Entity)-[r]->(person:Entity)
            WHERE (toLower(company.canonical_name) CONTAINS toLower($name)
                   OR toLower(company.id) CONTAINS toLower($name))
              AND (type(r) IN ['EMPLOYS', 'LED_BY', 'HAS_CEO', 'HAS_DIRECTOR', 
                               'BENEFICIAL_OWNER_OF', 'CONTROLLED_BY']
                   OR 'PERSON' IN labels(person))
            RETURN DISTINCT person.canonical_name as name, 
                   person.id as id,
                   type(r) as role
            LIMIT $limit
            """
            
            with self.graph_store.driver.session() as session:
                result = session.run(query, name=company_name, limit=max_directors)
                directors = list(result)
            
            results["directors_found"] = [
                {"name": d["name"], "role": d["role"]} for d in directors
            ]
            
            if not directors:
                logger.info("no_directors_found", company=company_name)
                return results
            
            # Step 2: Ghost-scan each director
            analyzer = NegativeSpaceAnalyzer()
            
            for director in directors:
                director_name = director["name"]
                if not director_name:
                    continue
                
                # Run ghost scan
                ghost_report = await analyzer.analyze(
                    target=director_name,
                    target_type="PERSON",
                    existing_data=None  # Fresh scan
                )
                
                scan_result = {
                    "name": director_name,
                    "role": director["role"],
                    "suspicion_level": ghost_report.overall_suspicion.value,
                    "void_score": ghost_report.void_score,
                    "anomalies": [
                        {
                            "type": a.anomaly_type,
                            "description": a.description
                        }
                        for a in ghost_report.anomalies
                    ]
                }
                
                results["directors_scanned"].append(scan_result)
                
                # Categorize
                if ghost_report.overall_suspicion in [SuspicionLevel.HIGH, SuspicionLevel.CRITICAL]:
                    results["suspicious_directors"].append(scan_result)
                else:
                    results["clean_directors"].append(director_name)
            
            # Step 3: Calculate overall company risk from director scans
            suspicious_count = len(results["suspicious_directors"])
            total_scanned = len(results["directors_scanned"])
            
            if suspicious_count >= 2:
                results["overall_company_risk"] = "HIGH"
            elif suspicious_count == 1:
                results["overall_company_risk"] = "MEDIUM"
            else:
                results["overall_company_risk"] = "LOW"
            
            logger.info(
                "cascade_scan_complete",
                company=company_name,
                directors_scanned=total_scanned,
                suspicious=suspicious_count
            )
            
        except Exception as e:
            logger.error("cascade_scan_failed", error=str(e))
            results["error"] = str(e)
        
        return results
    
    async def deep_analyze(self, user_input: str) -> Dict[str, Any]:
        """
        ENHANCED ANALYSIS: Includes director cascade for companies.
        
        Use this instead of analyze() for thorough investigation.
        """
        # Run standard analysis
        result = await self.analyze(user_input)
        
        # If COMPANY: Also scan directors
        if result["profile"]["target_type"] == "COMPANY":
            cascade_results = await self.cascade_scan_directors(user_input)
            result["director_scan"] = cascade_results
            
            # Add alert if suspicious directors found
            if cascade_results["suspicious_directors"]:
                result["alerts"].append({
                    "alert_type": "SUSPICIOUS_DIRECTORS",
                    "risk_level": "HIGH",
                    "message": f"{len(cascade_results['suspicious_directors'])} dirigeants suspects détectés",
                    "evidence": [
                        f"{d['name']} ({d['role']}): {d['suspicion_level']}"
                        for d in cascade_results["suspicious_directors"]
                    ],
                    "recommendation": "Vérification approfondie des dirigeants requise"
                })
        
        return result

